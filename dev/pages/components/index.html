<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Components · Susi</title><link rel="canonical" href="https://andreasdominik.github.io/Susi/dev/pages/components/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../../assets/logo.svg" alt="Susi logo"/></a><div class="docs-package-name"><span class="docs-autofit">Susi</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../install/">Installation</a></li><li><a class="tocitem" href="../configuration/">Configuration</a></li><li class="is-active"><a class="tocitem" href>Components</a><ul class="internal"><li><a class="tocitem" href="#Hotword-detection-1"><span>Hotword detection</span></a></li><li><a class="tocitem" href="#Record-1"><span>Record</span></a></li><li><a class="tocitem" href="#Speech-to-text-(STT)-1"><span>Speech to text (STT)</span></a></li><li><a class="tocitem" href="#Text-to-speech-(TTS)-1"><span>Text to speech (TTS)</span></a></li><li><a class="tocitem" href="#Play-1"><span>Play</span></a></li><li><a class="tocitem" href="#Session-manager-1"><span>Session manager</span></a></li><li><a class="tocitem" href="#NLU-natural-language-understanding-1"><span>NLU - natural language understanding</span></a></li></ul></li><li><a class="tocitem" href="../nlu/">NLU</a></li><li><a class="tocitem" href="../payloads/">Payloads</a></li><li><a class="tocitem" href="../topics/">Topics</a></li><li><a class="tocitem" href="../tools/">Tools</a></li><li><a class="tocitem" href="../../LICENSE/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Components</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Components</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/andreasdominik/Susi/blob/master/docs/src/pages/components.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Daemons-and-components-1"><a class="docs-heading-anchor" href="#Daemons-and-components-1">Daemons and components</a><a class="docs-heading-anchor-permalink" href="#Daemons-and-components-1" title="Permalink"></a></h1><h2 id="Hotword-detection-1"><a class="docs-heading-anchor" href="#Hotword-detection-1">Hotword detection</a><a class="docs-heading-anchor-permalink" href="#Hotword-detection-1" title="Permalink"></a></h2><p>By default, Snowboy is used as hotword detector, because of its high accuracy.</p><h2 id="Record-1"><a class="docs-heading-anchor" href="#Record-1">Record</a><a class="docs-heading-anchor-permalink" href="#Record-1" title="Permalink"></a></h2><p>The Swiss Army knife of sound processing programs (SoX - Sound eXchange) is used as default recording service. The following rec-command records audio with the configuration:</p><ul><li>maximum lenght TIME_MAX seconds</li><li>wait with recording until a sound is detected (no silence)</li><li>stop recording if 1 second of silence is recorded</li><li>remix to one channel</li><li>use a bitrate of 16000</li><li>add 10 dB of gain</li></ul><pre><code class="language-none">rec --rate 16000 $AUDIO \
    trim 0 $TIME_MAX \
    silence 1 0:00.05 $NOISE 1 $END_TRIGGER $NOISE \
    remix 1-2 \
    gain 10</code></pre><h2 id="Speech-to-text-(STT)-1"><a class="docs-heading-anchor" href="#Speech-to-text-(STT)-1">Speech to text (STT)</a><a class="docs-heading-anchor-permalink" href="#Speech-to-text-(STT)-1" title="Permalink"></a></h2><p>Speech recognition is the cruical part of every assistant. Unfortunately not very much open software with the desired quality is available currently.</p><p>There are a number of potentially usable open software available, such as</p><ul><li><strong>Mozilla DeepSpeech</strong> (https://github.com/mozilla/DeepSpeech), for which a binary is already included in the distribution.</li><li><strong>Kaldi</strong> (http://kaldi-asr.org/) provides already some high-quality model for different languages</li><li>For Facebook&#39;s <strong>wav2letter</strong> (https://github.com/facebookresearch/wav2letter) trained models are available, too.</li><li>High-quality trained models and tools are also provided by <strong>Zamia AI</strong> (http://zamia-speech.org/asr/).</li></ul><p>In contrast, commercial web-services with almost perfect quality are availble, such as:</p><ul><li>Google Cloud Speech-to-Text (https://cloud.google.com/speech-to-text/),</li><li>Wit.ai (https://wit.ai),</li><li>Google Dialogue Flow (https://dialogflow.com/),</li><li>Microsoft Cognitive Services (https://azure.microsoft.com/en-us/services/cognitive-services),</li><li>Watson Speech to Text (https://www.ibm.com/cloud/watson-speech-to-text),</li><li>Speechmatics (https://www.speechmatics.com/),</li><li>Amazon (https://aws.amazon.com/transcribe/)</li><li>etc.</li></ul><p>All of them require sending the recorded audio to the server somewhere in the internet, which breaks the privacy we are used to with Snips.ai.</p><p>However, speech recognition technology develops very fast and using a cloud service may be necessary for a period of transition, until locally installed and <em>open</em> software with compareble is available.</p><h3 id="Google-Cloud-STT-1"><a class="docs-heading-anchor" href="#Google-Cloud-STT-1">Google Cloud STT</a><a class="docs-heading-anchor-permalink" href="#Google-Cloud-STT-1" title="Permalink"></a></h3><p>The Google Cloud connector is configured by default in Susi, because of the very high quality of the transcriptions. The service ist sensitive, accurate available for many languages and has a good common knowlegde (knows names of famous persons, titles of movies and TV shows, etc.).</p><h4 id="Configuration-of-Google-Cloud-services:-1"><a class="docs-heading-anchor" href="#Configuration-of-Google-Cloud-services:-1">Configuration of Google Cloud services:</a><a class="docs-heading-anchor-permalink" href="#Configuration-of-Google-Cloud-services:-1" title="Permalink"></a></h4><p>If google services are used for text-to-speech (TTS) or speech-to-text (STT) the required softwate must be set up: Go through Google&#39;s tutorial <a href="https://cloud.google.com/text-to-speech/docs/quickstart-protocol">Quickstart: Using the command line</a>.</p><p>In summary ...</p><ul><li>a Google Cloud Platform Project is needed,</li><li>the Cloud Text-to-Speech API must be enabled and</li><li>the JSON-file with the credentials must be downloaded to <code>/opt/Susi/ApplicationData/Google/Credentials/google-credentials.json</code>     Path and filename may differ - they are specified in the susi configuration file.</li><li>the path to the credentials file must be made available by an variable. Edit the file <code>.bashrc</code> in the home directory of the user who will later run the assistent (e.g. <code>susi</code>) and add the line:    </li></ul><p><code>export GOOGLE_APPLICATION_CREDENTIALS=&quot;/opt/Susi/ApplicationData/Google/Credentials/google-credentials.json&quot;</code>         To check the installation run the following command.     It should print an access token, which can be uses to access the Cloud     Text-to-Speech API:</p><pre><code class="language-none">gcloud auth application-default print-access-token</code></pre><h3 id="IBM-Cloud-services-1"><a class="docs-heading-anchor" href="#IBM-Cloud-services-1">IBM Cloud services</a><a class="docs-heading-anchor-permalink" href="#IBM-Cloud-services-1" title="Permalink"></a></h3><p>Transcription quality  of IBM Cloud STT is sufficent for an assistant. (At least) in Europe the latency is smaller compared to the Google service (approx. half).</p><h4 id="Configuration-of-IBM-Cloud-services-1"><a class="docs-heading-anchor" href="#Configuration-of-IBM-Cloud-services-1">Configuration of IBM Cloud services</a><a class="docs-heading-anchor-permalink" href="#Configuration-of-IBM-Cloud-services-1" title="Permalink"></a></h4><p>To use IBM Watson Text to Speech STT or TTS, it must be configured as described on IBM&#39;s website: https://cloud.ibm.com/.</p><p>Is is as simple as:</p><ul><li>create an account</li><li>descide for a pricing plan (the &quot;Free Lite Plan&quot; may be sufficient as it offers up to 500 minutes of audio transcription and 10000 characters for TTS per month)</li><li>create a Speech to Text Service (and a Text to Sppech Service)</li><li>download the credential file <code>ibm-cedentials.env</code>, rename and save it at <code>/opt/Susi/ApplicationData/IBMCloud/ibm-tts-cedentials.env</code> (the download link is in the   &#39;Manage&#39; section)</li><li>work through the &quot;Getting started with Sppech to Text&quot; tutorial (https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-gettingStarted#getting-started-tutorial).</li></ul><p>Similar steps are necessary for text to speech. Please notice, that there are different credentials necessary for STT and TTS. Both need to be downloaded and saved to <code>/opt/Susi/ApplicationData/IBMCloud/</code> with different names (such as &#39;ibm-tts-cedentials.env&#39; and &#39;ibm-stt-cedentials.env&#39;). Names can be configured in the &#39;susi.toml&#39; file.</p><h3 id="Mozilla-DeepSpeech-1"><a class="docs-heading-anchor" href="#Mozilla-DeepSpeech-1">Mozilla DeepSpeech</a><a class="docs-heading-anchor-permalink" href="#Mozilla-DeepSpeech-1" title="Permalink"></a></h3><p>As an alternative to the Google Cloud services Mozilla DeepSpeech can be used. However,</p><ul><li>trained models and language models are only available for English langage</li><li>the quality of transcription seems not to be sufficient for an assistant (at least in my tests - this may differ for other speakers and different hardware)</li><li>a transcription needs 2-5 seconds.</li></ul><p>However, it is easily possible to set up a separate STT-server with sufficient CPU power (and maybe a GPU) and integrate it to Susi.</p><h4 id="Installation-of-Mozilla-DeepSpeech-1"><a class="docs-heading-anchor" href="#Installation-of-Mozilla-DeepSpeech-1">Installation of Mozilla DeepSpeech</a><a class="docs-heading-anchor-permalink" href="#Installation-of-Mozilla-DeepSpeech-1" title="Permalink"></a></h4><p>Installation is simple and follows the instruction on the website (https://github.com/mozilla/DeepSpeech). The installation can be tested by running deepspeech on the commandline.</p><p>DeepSpeech integration to Susi is already included in the distribution and can be activated by uncommenting the line in the configuration file.</p><pre><code class="language-none"># installation of Mozilla DeepSpeech:
#
# prepare:
mkdir /opt/DeepSpeech
cd /opt/DeepSpeech
virtualenv -p python3 ./deepspeech-venv/
source $HOME/tmp/deepspeech-venv/bin/activate

# Install DeepSpeech
pip3 install deepspeech

# Download pre-trained English model and extract
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz
tar xvf deepspeech-0.6.1-models.tar.gz

# Download example audio files
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/audio-0.6.1.tar.gz
tar xvf audio-0.6.1.tar.gz

# Transcribe an audio file
rec -r 16000 lighton.wav

deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio lighton.wav</code></pre><h3 id="Snips-ASR-1"><a class="docs-heading-anchor" href="#Snips-ASR-1">Snips ASR</a><a class="docs-heading-anchor-permalink" href="#Snips-ASR-1" title="Permalink"></a></h3><p>The ASR component of Snips takes its power from the integration with NLU; i.e. the ASR knows all sentences and phrases that must be recognised and hence the language model can be adapted to each individual assistant. Because the Snips Console (the Web-interface to Snips ASR and NLU) is no longer open for the public, it is no longer possible to train the speech recognition for new skills.</p><p>Two potential ways to use Snips ASR still remain:</p><ul><li>A <strong>customised trained existing model</strong> can be used, as long as no new Skills and intents are added to an assistant, that hase been downloaded from the Snips console.</li><li>Snips provides a pretrained <strong>general model for English language</strong> that can be used for any intent. However, the model is huge, compared to the customised models, and therefore transcription needs several seconds on a Raspberry pi. To use the model, it is recommended to install the STT component on a more powerful headless server (such as a NUC or a discarded laptop).</li></ul><p>If a trained model is available and Snips ASR is installed, it can be activated by selecting the respective binary in the STT section of the configuration file &#39;susi.toml.</p><h4 id="Installation-and-configuration-od-Snips-ASR-1"><a class="docs-heading-anchor" href="#Installation-and-configuration-od-Snips-ASR-1">Installation and configuration od Snips ASR</a><a class="docs-heading-anchor-permalink" href="#Installation-and-configuration-od-Snips-ASR-1" title="Permalink"></a></h4><p>To install the Snips asr</p><ul><li>add the Snips apt-get repository,</li><li>install snips-asr,</li><li>make sure that the service is not runing (Susi will start asr when it needs it),</li><li>if you have no personally trained model, there is a general model (English language only) that can be used:</li></ul><pre><code class="language-none">sudo bash -c  &#39;echo &quot;deb https://debian.snips.ai/stretch stable main&quot; &gt; /etc/apt/sources.list.d/snips.list&#39;
sudo apt-key adv --fetch-keys  https://debian.snips.ai/5FFCD0DEB5BA45CD.pub
sudo apt-get update
sudo apt-get install snips-asr
sudo systemctl stop snips-asr
sudo systemctl disable snips-asr

# the general model:
# sudo apt-get install snips-asr-model-en-500mb</code></pre><p>A version of the general model is incuded inthe Susi distribution and strored at &#39;/opt/Susi/ApplicationData/Snips/ASRmodels&#39;. To use it, just unpack it:</p><pre><code class="language-none">cd /opt/Susi/ApplicationData/Snips/ASRmodels
tar xvf snips-asr-model-en-500MB.tar.gz</code></pre><p>In the STT section of the configuration file &#39;susi.toml&#39; the binary must be set to <code>snips-asr</code> (just uncomment the respective line) and to use the general model, the model path must point to the directory to which the model was saved.</p><h2 id="Text-to-speech-(TTS)-1"><a class="docs-heading-anchor" href="#Text-to-speech-(TTS)-1">Text to speech (TTS)</a><a class="docs-heading-anchor-permalink" href="#Text-to-speech-(TTS)-1" title="Permalink"></a></h2><h4 id="Google-Cloud-TTS-1"><a class="docs-heading-anchor" href="#Google-Cloud-TTS-1">Google Cloud TTS</a><a class="docs-heading-anchor-permalink" href="#Google-Cloud-TTS-1" title="Permalink"></a></h4><p>Google&#39;s text to speech service is used as default service, because it provides the most realistic voices. In order to reduce calls to the Google Cloud, all retrieved audio will be cached and reused if the same sentence is needed again.</p><p>Available voices can be tested here: https://cloud.google.com/text-to-speech.</p><h4 id="Mozilla-1"><a class="docs-heading-anchor" href="#Mozilla-1">Mozilla</a><a class="docs-heading-anchor-permalink" href="#Mozilla-1" title="Permalink"></a></h4><p>Mozilla&#39;s Deep Voice is not yet implemented.</p><h4 id="IBM-Cloud-TTS-1"><a class="docs-heading-anchor" href="#IBM-Cloud-TTS-1">IBM Cloud TTS</a><a class="docs-heading-anchor-permalink" href="#IBM-Cloud-TTS-1" title="Permalink"></a></h4><p>The connector to the IBM Clouds text-to-speech service is alrady included in the distribution. It can be selected by uncommenting the respective line for the binary in the <code>[tts]</code>-section of the configuration file &#39;susi.toml&#39;.</p><p>Please notice, that there are different credentials for STT and TTS.</p><p>Example voices can be listened to at: https://www.ibm.com/de-de/cloud/watson-text-to-speech and https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voices.</p><h2 id="Play-1"><a class="docs-heading-anchor" href="#Play-1">Play</a><a class="docs-heading-anchor-permalink" href="#Play-1" title="Permalink"></a></h2><p>Susi&#39;s play component uses linux sox play (SoX - Sound eXchange). The play.daemon subscribes to the topic &#39;susi/playserver/request&#39;with a payload that include a base64-encoded audio file and the siteId on which the audio must be played.</p><p>The daemon can play all audio formats that sox play is able to play (for mp3 &#39;libsox-fmt-mp3&#39; must be installed).</p><p>The length of the audio is not limited.</p><p>It is recommended not to send requests directly to the play daemon, but use the session manager API instead (topic: &#39;susi/play/playAudio&#39;). This ensures that timeouts are postponed during playing.</p><h2 id="Session-manager-1"><a class="docs-heading-anchor" href="#Session-manager-1">Session manager</a><a class="docs-heading-anchor-permalink" href="#Session-manager-1" title="Permalink"></a></h2><p>The session manager runs sequences of actions, such as <code>hotword -&gt; record -&gt; stt -&gt; nlu -&gt; publish intent</code> and takes care of timeouts and non-responding components.</p><h2 id="NLU-natural-language-understanding-1"><a class="docs-heading-anchor" href="#NLU-natural-language-understanding-1">NLU - natural language understanding</a><a class="docs-heading-anchor-permalink" href="#NLU-natural-language-understanding-1" title="Permalink"></a></h2><p>The NLU component replaces the Snips NLU and is independent from the Snips console. It is configured only with a configuration file <code>nlu-xx.toml</code> for each skill, where &#39;xx&#39; denotes a 2-letter language code. The nlu configuration files must be present somewhere in the skills directory.</p><p>The files are in standard toml format, constisting of &#39;key&#39; -&gt; &#39;value&#39; pairs or &#39;key&#39; -&gt; &#39;list&#39; pairs. Lists with only one entry may be written as values (without brackets).</p><p>The nlu.xx.toml file includes the parts:</p><h4 id="head-1"><a class="docs-heading-anchor" href="#head-1">head</a><a class="docs-heading-anchor-permalink" href="#head-1" title="Permalink"></a></h4><p>The head defines the name of the configured skill and the name of the skill developer (the developer name is used to generate Snips-compatible intent names).</p><p>The inventory section lists all intents and slots configured and used in the file:</p><pre><code class="language-none"># head:
#
skill = &quot;RollerShutter&quot;
developer = &quot;andreasdominik&quot;

[inventory]
intents = [&quot;RollerUpDown&quot;]
slots = [&quot;room&quot;, &quot;device&quot;, &quot;Action&quot;]</code></pre><h4 id="Slot-definitions-1"><a class="docs-heading-anchor" href="#Slot-definitions-1">Slot definitions</a><a class="docs-heading-anchor-permalink" href="#Slot-definitions-1" title="Permalink"></a></h4><p>For each listed slot, a slot definition section must be present in the toml file, including the keys <code>slot_type</code>, optional <code>allow_empty</code> and an optional sub-section <code>&lt;slotname&gt;.synonyms</code>:</p><pre><code class="language-none"># slot definitions:
#
[room]
slot_type = &quot;ListOfValues&quot;
allow_empty = true

        [room.synonyms]
        &quot;house&quot; = [&quot;everywhere&quot;, &quot;in the house&quot;, &quot;house&quot;]
        &quot;dining&quot; = [&quot;dining room&quot;, &quot;dining&quot;]
        &quot;stairs&quot; = [&quot;staircase&quot;, &quot;stairs&quot;]
        &quot;kitchen&quot; = &quot;kitchen&quot;
        &quot;bedroom&quot; = [&quot;bedroom&quot;, &quot;parents bedroom&quot;]</code></pre><p><strong>slot_type</strong> is one of &#39;ListOfValues&#39;, &#39;Any&#39;, &#39;Number&#39;, &#39;Ordinal&#39; or &#39;Time&#39;; see below for details.     If <strong>allow_empty</strong> is specified as true, an expression will match, even if the slot is not parsed. If the key &#39;allow_empty&#39; is missing, the default <code>false</code> is assumed.</p><h5 id="Slot-type-ListOfValues-1"><a class="docs-heading-anchor" href="#Slot-type-ListOfValues-1">Slot type ListOfValues</a><a class="docs-heading-anchor-permalink" href="#Slot-type-ListOfValues-1" title="Permalink"></a></h5><p>A slot type &#39;ListOfValues&#39; needs a mandatory subsection with synonymes, consisting of alternatives with a name and a list of values. In contrast to Snips, the names are not included in the list.</p><p>When parsing a command the slot will match if one of the words or phrases in one of the lists is recognised, and the name of the respective synonym is returned as slot value. This way it is easy to write language-independent skill code, because the returned slot values are indepentent from the actual parsed commands.</p><h5 id="Slot-type-Any-1"><a class="docs-heading-anchor" href="#Slot-type-Any-1">Slot type Any</a><a class="docs-heading-anchor-permalink" href="#Slot-type-Any-1" title="Permalink"></a></h5><p>A slot of tyle &#39;Any&#39; will match any word or phrase.</p><p>In addition it is possible to add synonyms to a slot of type Any.</p><h5 id="Slot-types-Number,-Ordinal-and-Time-1"><a class="docs-heading-anchor" href="#Slot-types-Number,-Ordinal-and-Time-1">Slot types Number, Ordinal and Time</a><a class="docs-heading-anchor-permalink" href="#Slot-types-Number,-Ordinal-and-Time-1" title="Permalink"></a></h5><p>Slots of one of these types will be extracted from the command and passed to Duckling to get a number or timestring.</p><h4 id="Intent-definition-1"><a class="docs-heading-anchor" href="#Intent-definition-1">Intent definition</a><a class="docs-heading-anchor-permalink" href="#Intent-definition-1" title="Permalink"></a></h4><p>The last part of the configuration file holds <em>match phrases</em>, which are compared with transcribed commands to identify intents (actions to be executed within skills) and to extract slot values. The following rukles apply:</p><ul><li>each intent is configured in a separate section of the toml file <code>[intentname]</code></li><li>several match phrases may be defined for each intent</li><li>each match phrase constists of a <em>name</em>, a <em>type</em> and the phrase to be matched</li><li>match phrases are matched in alphabetic order of their names</li><li>a match phrase can be of type &#39;regex&#39;, &#39;complete&#39;, &#39;partial&#39; or &#39;ordered&#39;.</li></ul><h5 id="match-phrase-type-regex-1"><a class="docs-heading-anchor" href="#match-phrase-type-regex-1">match phrase type regex</a><a class="docs-heading-anchor-permalink" href="#match-phrase-type-regex-1" title="Permalink"></a></h5><p>It is possible to write match phrases as Perl-compatible regular expresisons with a syntax, provided b ythe PCRE library (see http://www.pcre.org/current/doc/html/pcre2syntax.html for the syntax). Slots are defined as named capture groups with the slot name as capture group name.</p><h5 id="match-phrase-type-complete-1"><a class="docs-heading-anchor" href="#match-phrase-type-complete-1">match phrase type complete</a><a class="docs-heading-anchor-permalink" href="#match-phrase-type-complete-1" title="Permalink"></a></h5><p>To avoid the need to writing plain regular expressions, the types &#39;complete&#39;, &#39;partial&#39; and &#39;ordered&#39; provide an easier interface.</p><p>For complete&#39;, the phrase is just a sentence that must match completely, with several types of placeholders allowed:</p><ul><li><strong>&lt;&lt;slotname&gt;&gt;:</strong> the slot is expected at this position. If the slot si configured as <code>allow_empty = true</code>, the phrase will match even if the slot is not present.</li><li><strong>&lt;&lt;word1|words and more|word3&gt;&gt;:</strong> one of the listed words or phrases is expected at this position. Words are separated by the pipe charater <code>|</code>. An empty alternative (&lt;&lt;word1|words and more|&gt;&gt; or &lt;&lt;word1||words and more&gt;&gt;) will match missing words as well.</li><li><strong>&lt;&lt;&gt;&gt;:</strong> the empty placeholder will match exactly one or no words.</li></ul><p>Examples:     the match phrase  </p><pre><code class="language-none">[RollerUpDown]
roller_a = &quot;complete: &lt;&lt;action&gt;&gt; the &lt;&lt;rollershutter|roller&gt;&gt; &lt;&lt;in|&gt;&gt; &lt;&lt;the|&gt;&gt; &lt;&lt;room&gt;&gt;&quot;</code></pre><p>will match the commands <code>&quot;Open the rollershutter in the kitchen&quot;</code> and <code>&quot;Open the rollershutter in kitchen&quot;</code> as well as <code>&quot;Open the rollershutter&quot;</code>, because the placeholders &quot;&lt;&lt;in|&gt;&gt;&quot; and &quot;&lt;&lt;the|&gt;&quot; allow empty values and &quot;&lt;&lt;room&gt;&gt;&quot; is allowed to be empty as well.</p><p>However the match phrase will <strong>not</strong> match <code>&quot;Please open the rollershutter in the kitchen&quot;</code>, because not the complete phrase mathes.</p><p>To be more specific optional words may be added, such as</p><pre><code class="language-none">roller_b = &quot;complete: &lt;&lt;please|&gt;&gt; &lt;&lt;action&gt;&gt; the &lt;&lt;rollershutter|roller&gt;&gt; &lt;&lt;in|&gt;&gt; &lt;&lt;the|&gt;&gt; &lt;&lt;room&gt;&gt; &lt;&lt;please|&gt;&gt;&quot;</code></pre><h5 id="match-phrase-type-partial-1"><a class="docs-heading-anchor" href="#match-phrase-type-partial-1">match phrase type partial</a><a class="docs-heading-anchor-permalink" href="#match-phrase-type-partial-1" title="Permalink"></a></h5><p>Match phrases of type &#39;partial&#39; follow the same rules as of type &#39;complete&#39;, with the difference that only parts of the command must match the phrase.</p><p>Examples: the match phrase</p><pre><code class="language-none">[RollerUpDown]
roller_b = &quot;partial: &lt;&lt;action&gt;&gt; the &lt;&lt;rollershutter|roller&gt;&gt; &lt;&lt;in|&gt;&gt; &lt;&lt;the|&gt;&gt; &lt;&lt;room&gt;&gt;&quot;</code></pre><p>will match <code>&quot;Please open the rollershutter in the kitchen&quot;</code> as well as <code>&quot;Please open the rollershutter in the kitchen and get me a coffee&quot;</code>.</p><h5 id="match-phrase-type-ordered-1"><a class="docs-heading-anchor" href="#match-phrase-type-ordered-1">match phrase type ordered</a><a class="docs-heading-anchor-permalink" href="#match-phrase-type-ordered-1" title="Permalink"></a></h5><p>Match phrases of type &#39;ordered&#39; follow the same rules but are more vague, as only all words of the match phrase must be present in the command in the correct order. Additional words may be present before, after or inbetween.</p><h4 id="Example-file-nlu-xx.toml-for-the-rollershutter-skill:-1"><a class="docs-heading-anchor" href="#Example-file-nlu-xx.toml-for-the-rollershutter-skill:-1">Example file nlu-xx.toml for the rollershutter skill:</a><a class="docs-heading-anchor-permalink" href="#Example-file-nlu-xx.toml-for-the-rollershutter-skill:-1" title="Permalink"></a></h4><p>A complete (but very simple and not yet sufficent) example nlu configuration file is shown in a version vor 3 different languages. It must be pointet out, that the slot values extracted to the intent are exactly the same for all languages, which makes it easy to write language-intependant skill code.</p><h5 id="nlu-en.toml-1"><a class="docs-heading-anchor" href="#nlu-en.toml-1">nlu-en.toml</a><a class="docs-heading-anchor-permalink" href="#nlu-en.toml-1" title="Permalink"></a></h5><pre><code class="language-none"># nlu definition for RollerShutter skill
#
# head:
#
skill = &quot;RollerShutter&quot;
developer = &quot;andreasdominik&quot;

[inventory]
intents = [&quot;RollerUpDown&quot;]
slots = [&quot;room&quot;, &quot;Action&quot;]


# slot definitions:
#
[room]
slot_type = &quot;ListOfValues&quot;
allow_empty = true

        [room.synonyms]
        &quot;house&quot; = [&quot;everywhere&quot;, &quot;in the house&quot;, &quot;house&quot;]
        &quot;dining&quot; = [&quot;dining room&quot;, &quot;dining&quot;]
        &quot;stairs&quot; = [&quot;staircase&quot;, &quot;stairs&quot;]
        &quot;kitchen&quot; = &quot;kitchen&quot;
        &quot;bedroom&quot; = [&quot;bedroom&quot;, &quot;parents bedroom&quot;]

[action]
slot_type = &quot;ListOfValues&quot;

        [action.synonyms]
        &quot;open&quot; = [&quot;open&quot;, &quot;up&quot;]
        &quot;close&quot; = [&quot;close&quot;, &quot;down&quot;, &quot;shut&quot;]

# match phrases for intent recognion:
#
[RollerUpDown]
roller_a = &quot;partial: &lt;&lt;action&gt;&gt; the &lt;&lt;rollershutter|roller&gt;&gt; &lt;&lt;in|&gt;&gt; &lt;&lt;the|&gt;&gt; &lt;&lt;room&gt;&gt;&quot;
roller_b = &quot;complete: &lt;&lt;please|&gt;&gt; make the &lt;&lt;rollershutter|roller&gt;&gt; in the &lt;&lt;room|&gt;&gt; &lt;&lt;room&gt;&gt; &lt;&lt;action&gt;&gt; &lt;&lt;please|&gt;&gt;&quot;
roller_c = &quot;partial: make the &lt;&lt;rollershutter|roller&gt;&gt; &lt;&lt;&gt;&gt; &lt;&lt;action&gt;&gt;&quot;</code></pre><h5 id="nlu-fr.toml-1"><a class="docs-heading-anchor" href="#nlu-fr.toml-1">nlu-fr.toml</a><a class="docs-heading-anchor-permalink" href="#nlu-fr.toml-1" title="Permalink"></a></h5><pre><code class="language-none"># nlu definition for RollerShutter skill
#
# head:
#
skill = &quot;RollerShutter&quot;
developer = &quot;andreasdominik&quot;

[inventory]
intents = [&quot;RollerUpDown&quot;]
slots = [&quot;room&quot;, &quot;Action&quot;]


# slot definitions:
#
[room]
slot_type = &quot;ListOfValues&quot;
allow_empty = true

        [room.synonyms]
        &quot;house&quot; = [&quot;partout dans la maison&quot;, &quot;dans toute la maison&quot;, &quot;maison&quot;]
        &quot;dining&quot; = &quot;salle à manger&quot;
        &quot;stairs&quot; = [&quot;cage d&#39;escalier&quot;]
        &quot;kitchen&quot; = &quot;cuisine&quot;
        &quot;bedroom&quot; = [&quot;chambre&quot;]

[action]
slot_type = &quot;ListOfValues&quot;

        [action.synonyms]
        &quot;open&quot; = [&quot;ouvrir&quot;, &quot;ouvrez&quot;]
        &quot;close&quot; = [&quot;fermez&quot;]

# match phrases for intent recognion:
#
[RollerUpDown]
roller_a = &quot;&lt;&lt;veuillez|&gt;&gt; &lt;&lt;action&gt;&gt; &lt;&lt;le volet roulant|les volets|le volet&gt;&gt; &lt;&lt;de la|dans la|&gt;&gt; &lt;&lt;room&gt;&gt; &lt;&lt;s&#39;il vous plaît|&gt;&gt;&quot;</code></pre><h5 id="nlu-de.toml-1"><a class="docs-heading-anchor" href="#nlu-de.toml-1">nlu-de.toml</a><a class="docs-heading-anchor-permalink" href="#nlu-de.toml-1" title="Permalink"></a></h5><pre><code class="language-none"># nlu definition for RollerShutter skill
#
# head:
#
skill = &quot;RollerShutter&quot;
developer = &quot;andreasdominik&quot;

[inventory]
intents = [&quot;RollerUpDown&quot;]
slots = [&quot;room&quot;, &quot;Action&quot;]


# slot definitions:
#
[room]
slot_type = &quot;ListOfValues&quot;
allow_empty = true

        [room.synonyms]
        &quot;house&quot; = [&quot;überall&quot;, &quot;im ganzen Haus&quot;, &quot;Haus&quot;]
        &quot;dining&quot; = &quot;Esszimmer&quot;
        &quot;stairs&quot; = [&quot;Treppenhaus&quot;, &quot;Treppe&quot;]
        &quot;kitchen&quot; = &quot;Küche&quot;
        &quot;bedroom&quot; = [&quot;schlafzimmer&quot;]

[action]
slot_type = &quot;ListOfValues&quot;

        [action.synonyms]
        &quot;open&quot; = [&quot;auf&quot;, &quot;nach oben&quot;, &quot;öffne&quot;]
        &quot;close&quot; = [&quot;zu&quot;, &quot;herunter&quot;, &quot;runter&quot;, &quot;schließe&quot;]

# match phrases for intent recognion:
#
[RollerUpDown]
roller_a = &quot;partial: &lt;&lt;bitte|&gt;&gt; &lt;&lt;action&gt;&gt; &lt;&lt;bitte|&gt;&gt; den &lt;&lt;Rolladen|Rollo&gt;&gt; &lt;&lt;in der|im|&gt;&gt; &lt;&lt;room&gt;&gt;&quot;
roller_c = &quot;partial: mach &lt;&lt;bitte|&gt;&gt; den &lt;&lt;Rolladen|Rollo&gt;&gt; &lt;&lt;in der|im&gt;&gt; &lt;&lt;room&gt;&gt; &lt;&lt;action&gt;&gt;&quot;
roller_d = &quot;partial: mach &lt;&lt;bitte|&gt;&gt; den &lt;&lt;Rolladen|Rollo&gt;&gt; &lt;&lt;action&gt;&gt;&quot;</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../configuration/">« Configuration</a><a class="docs-footer-nextpage" href="../nlu/">NLU »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 14 March 2020 09:00">Saturday 14 March 2020</span>. Using Julia version 1.2.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
